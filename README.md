# Transition-Based Dependency Parsing

In this project, I use transition-based dependency parsing to obtain dependency relations among words in sentence. The training corpus used is the WSJ part of Penn Treebank, which contains sentence representations that are annotated in CoNNL format. I use a neural network with an embedding layer and 3 dense layers with a softmax output to predict the transition made by the parser. First, I created input/output representations for the network . The inputs represented a state of the parser and contained the first 3 words on the buffer and the top 3 words on the stack. The outputs were one-hot-encoded vectors representing the transition and the depndency label. Next, I trained the notebook on Colab using its free K80 GPU. Lastly, I implemented the standard transition-based algorithm to create valid dependency structures.
